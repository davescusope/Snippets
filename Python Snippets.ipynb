{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Snippets for Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyboard Shortcuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Command Mode </b>\n",
    "\n",
    "Press Esc to enable the Command Mode and then press H to enter in the Keyboard Shortcuts Guide (Blue Color labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift + enter -- run cell, select below\n",
    "# ctrl + enter -- run cell\n",
    "# option (left Alt) + enter -- run cell, insert below\n",
    "# A -- insert cell above\n",
    "# B -- insert cell below\n",
    "# C -- copy cell\n",
    "# V -- paste cell\n",
    "# D , D -- delete selected cell\n",
    "# I , I -- interrupt kernel\n",
    "# 0 , 0 -- restart kernel (with dialog)\n",
    "# Y -- change cell to code mode\n",
    "# M -- change cell to markdown mode (good for documentation)\n",
    "# shift + M -- merge selected cells, or current cell with cell below if only one cell selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Edit Mode </b>\n",
    "\n",
    "Press in any cell to enable the Edit Mode on it (Green Color labeled) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctrl + click -- multi-cursor editing\n",
    "# option + scrolling click -- column editing\n",
    "# ctrl + /  -- toggle comment lines\n",
    "# ctrl + ç  -- toggle comment lines\n",
    "# tab -- code completion or indent\n",
    "# shift + tab -- tooltip on selection\n",
    "# ctrl + shift + - split cell in two (Edit Mode) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magic Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%timeit\n",
    "df.unstack?\n",
    "help[df.unstack]\n",
    "history                 #muestra el historial de comandos ejecutados en el notebook\n",
    "! ls\n",
    "! pwd                   #devuelve la ruta donde estamos trabajando\n",
    "! cd                    #el cd de python sirve para moverme, despues de moverse, vuelve automaticamente a la ruta inicial\n",
    "! bzcat ./bookings_sample.csv.bz2 | wc -l #nos dice cuantas lineas tiene el archivo que hemos importado\n",
    "!conda install --yes GeoBases #instala una libreria cualquiera en el directorio de conda, en este caso GeoBases\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import os as os\n",
    "import zipfile as zp\n",
    "import bz2     as bz2             # libreria estandar para archivos comprimidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('example.db') #Para conectar con una db de sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar archivos html\n",
    "from IPython.display import IFrame\n",
    "IFrame('readme.html', width=700, height=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importación y exportación de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining path to  file in the same folder as jupiter\n",
    "my_file_path='xxx.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar archivo de excel , Csv o SQlite\n",
    "df = pd.read_excel('out.xls', \n",
    "                    index_col=0, \n",
    "                    header=7, \n",
    "                    sheet='2010', \n",
    "                    skip_footer=1,\n",
    "                    usecols='A:K'))\n",
    "\n",
    "df = pd.read_csv(my_file_path)\n",
    "df.head()\n",
    "\n",
    "pd.read_sql_query('SELECT * FROM traffic WHERE SEATS > 160', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar archivo a excel o csv\n",
    "df.to_excel('out.xlsx')\n",
    "df.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acciones a realizar sobre los Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acciones de inspeccion del contenido\n",
    "\n",
    "df.describe()                                 # Devuelve una descripción del contenido con medidas arimeticas  \n",
    "df.shape                                      # Devuelve la forma del df \n",
    "df.dtypes                                     # Devuelve los tipos de datos \n",
    "df.size                                       # Devuelve el tamaño del df \n",
    "df.corr()                                     # Devuelve las correlaciones entre las columnas numericas del df\n",
    "df.count()                                    # Devuelve el count de las columnas \n",
    "df.info                                       # Devuelve información sobre el df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busquedas y funciones estadisticas sobre df's\n",
    "\n",
    "pd.set_option('display.max_columns',100)        #muestra 100 columnas\n",
    "pd.set_option('display.max_columns',None)       #para devolverlo a ninguna\n",
    "df[df['LUGAR'].str.startswith(\"ARDEMANS\").strip()]\n",
    "df[df['LUGAR'].str.contains(\"ARDEMANS\").strip()]\n",
    "df['IMP_BOL'].mean()\n",
    "df['IMP_BOL'].sum()\n",
    "df['IMP_BOL'].count()\n",
    "df['IMP_BOL'].max()\n",
    "df['IMP_BOL'].min()\n",
    "def peak_to_peak(s): #Maximo menos el mínimo\n",
    "    return s.max() - s.min()\n",
    "def rango_normal(s):#2 std por cada lado\n",
    "    return 4*s.std()\n",
    "\n",
    "\n",
    "# Data transformations\n",
    "df2=df1.copy()                                 # Crea una copia por valor y no por referencia\n",
    "df1.drop('column')\n",
    "df1.duplicated()                               # Boolean que informa de los duplicados\n",
    "df1[df1.duplicated()]                          # Se queda con los duplicados\n",
    "df1.drop_duplicates(keep='last',inplace=False) # Elimina los duplicados quedandose con el ultimo de ellos\n",
    "df1.isna                                       # Indicate missing values.\n",
    "df1.notna                                      # Indicate existing (non-missing) values.\n",
    "df1.fillna                                     # Replace missing values.\n",
    "df1.dropna                                     # Drop missing values.\n",
    "Index.dropna                                   # Drop missing indices.\n",
    "df1['data'].fillna.mean()                      # Rellena los vacios con el valor que le pongamos\n",
    "df1.index = list('plfjdmh')                    # Renombra el indice df1.index = range (7)\n",
    "\n",
    "df1.rename(columns={'age': 'is_just_a_number'}, inplace=True)\n",
    "df1.sort_values(by='DepDelay', ascending=False).head()\n",
    "\n",
    "\n",
    "# Numerical transformations\n",
    "df1 = np.arange(0,24).reshape(4,6)             # Creación de df y redimensionado con numpy\n",
    "np.round(df1.head(20),decimals=1)              # Redondea valores\n",
    "X = np.linspace(0, 10, 50)                     # Crea una linea de 50 puntos de rango  0 a 10\n",
    "X = np.random.randn(100)                       # Crea una nube de 100 puntos\n",
    "X = np.sin(X)\n",
    "X = np.cos(X)\n",
    "X = np.tanh(X)\n",
    "X = np.exp(X)\n",
    "ts = pd.to_datetime('2015-01-15 08:30')        # This is the format pd.to_datetime needs Timestamp('2015-01-15 08:30:00')\n",
    "\n",
    "\n",
    "\n",
    "# Acciones de entrelazado de df's \n",
    "\n",
    "df1.merge(df2) #si no se especifica, hace inner por la columna común segun el nombre de columna\n",
    "df1.merge(df2, how='inner')\n",
    "df1.merge(df2, how='outer')\n",
    "df1.merge(df2, how='left')\n",
    "df1.merge(df2, left_on='column_on_the_left', right_on='column_on_the_right')\n",
    "df1.merge(df2, on='key', suffixes=['_left', '_right'])\n",
    "df1.merge(df2, left_on='key', right_index=True) # merge on index\n",
    "\n",
    "pd.concat([df1, df5])           #concatena en el eje x\n",
    "pd.concat([df1, df5], axis = 1) #concatena en el eje y\n",
    "a = df.groupby('producto')['balance'].mean() #realiza un group by que devolverá la media de la columna balance según producto\n",
    "df1.groupby(['producto', 'vendedor']).agg(['mean', 'count']) #con agg lo que hacemos es poder pedir todas las funciones que queramos sobre una agregación de groupby\n",
    "                                                            #group by según producto y vendedor que devuelve la media y la cuenta de todas las columnas numericas\n",
    "df1.groupby('producto')['vendedor'].agg(lambda strseries: strseries.str.len().sum()) # en vez de usar una función definida, usa una labda creada para sumar los caracteres\n",
    "df1.groupby('market')['data'].apply(lambda x: x.fillna(x.mean())) # Podemos utilizar apply para aplicar una función sobre la serie\n",
    "                                                                    # Apply siempre espera una función como argumento\n",
    "df1.unstack('vendedor') #pivota la tabla como transpuesta sobre la columna vendedor\n",
    "df1.pivot(columns='vendedor')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#ejemplo que engloba todo lo anterior\n",
    "df[df['vendedor']=='Celia'].groupby('producto').mean().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#en pandas, cuando trabajamos con strings, hay que definirlo como tal\n",
    "#con pandas no hay qu definir ninguna fucnion lambda para que afecte sobre todos los elementos de la lista (map),\n",
    "#directamente pandas nos permite hacer transformaciones que ya afectan directamente a la serie entera\n",
    "\n",
    "animals_series.str\n",
    "animals.columns.str.strip()                #quita los espacios en los nombres de las columnas\n",
    "animals_series.str.split()\n",
    "animals_series.str.capitalize()\n",
    "animals_series.str.upper()\n",
    "animals_series.str.len()\n",
    "animals_series.str.count()\n",
    "animals_series.str.contains('m')\n",
    "df1['animals']=df1['animals'].str.upper() #cambio la columna animals por si misma pero en mayusculas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de archivo importado y navegación por él"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accidents = pd.read_excel(file_path, index_col=0, header=7, sheet_name=None)\n",
    "all_accidents['2009'] #por ejemplo\n",
    "list1 = all_accidents.keys()\n",
    "for year in list1:\n",
    "    print (year)\n",
    "    df2 = all_accidents[year]\n",
    "    df2['YEAR'] = year "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actuación si se elimina una función restringida en algún modulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(pd.concat) #se borra la función que hayamos renombrado y por ello ya no funciona la original\n",
    "import imp     #importamos imp y desde ahi recargamos pandas\n",
    "imp.reload(pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representación Gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ages,bins=bins)                   # Grafico tipo histograma donde le definimos los ejes y los intervalos que se llaman como nuestra lista (bins)\n",
    "plt.plot(X, X,'r--',label=r'lin');         # Grafico ordinario ; el -- hace que la linea sea discontinua\n",
    "plt.legend(['Sin', 'Identity'],loc=2);     # Leyenda del grafico\n",
    "plt.bar();                                 # Grafico de barras\n",
    "plt.scatter(x,y,color='b');                # Grafico de puntos\n",
    "plt.show()\n",
    "\n",
    "#Definimos una función para ver las posibilidades de modificación de parametros en plt\n",
    "def set_fig_props():\n",
    "    plt.rcParams['figure.figsize']=(10.0,8.0)\n",
    "    plt.rcParams['savefig.dpi']=300\n",
    "    plt.rcParams['figure.facecolor']='white'\n",
    "    sizefont=30\n",
    "    font={'family':'normal','weight':'normal','size':sizefont}\n",
    "    plt.rc('font',**{'family':'serif','serif':['Computer Modern'],'size':sizefont})\n",
    "    plt.rc('xtick',labelsize=sizefont)\n",
    "    plt.rc('ytick',labelsize=sizefont)\n",
    "\n",
    "    \n",
    "fig, axs = plt.subplots(2,2)                #Crea un plot de 4 subplots forma de matriz 2,2\n",
    "axs[0,0].plot (X,Y, 'r--')                  #recta discontinua roja\n",
    "axs[0,1].plot (X,X,c='purple' ,'bs')        #cuadrados azules \n",
    "axs[0,1].plot (X,X,c='purple' ,'g^')        # triangulos verdes\n",
    "axs[1,0].scatter (X2,Y2_randomized,c='green')\n",
    "axs[1,1].scatter (X,Y,c='blue')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gestión de errores try-except"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usa los try error por si acaso dan fallos al abrir el archivo\n",
    "filename2 = './bookings_sample.csv'\n",
    "try:\n",
    "    with open (filename2, \"r\") as file_input:\n",
    "        for p, line in enumerate(file_input):\n",
    "            pass\n",
    "\n",
    "    print ( \"%s has %d lines\"%(filename2, p+1))\n",
    "except IOError:\n",
    "    print (\"Error.File did not open\")\n",
    "except ValueError:\n",
    "    print(\"Cannot convert to integer\")\n",
    "except:\n",
    "    print(\"Unknown error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partición de ficheros grandes con iterator = true and get_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del fichero, no un data frame, pero al poner el iterator = True, corre un marcador donde al\n",
    "# ejecutarlo por segunda vez, nos sacaria las siguientes lineas\n",
    "\n",
    "df2 =pd.read_csv(filename2, sep='^', usecols=['year','pax','arr_port'],iterator = True)\n",
    "# nos devuelve una lecdtura del fichero, no un data frame, pero al poner el iterator = True, corre un marcador donde al\n",
    "# ejecutarlo por segunda vez, nos sacaria las siguientes lineas\n",
    "\n",
    "b0=df2.get_chunk(6000)\n",
    "b1=df2.get_chunk(3000) #traemos las siguientes 3000\n",
    "#..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora lo hacemos definiendo el tamaño maximo del chunk en vez de un iterator\n",
    "df2 =pd.read_csv(filename2, sep='^', usecols=['year','pax','arr_port'],chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc =pd.read_csv(filename2, sep='^', usecols=['year','pax','arr_port'],chunksize=1000)\n",
    "for i, chunk in enumerate(bc):\n",
    "    print(chunk.head())\n",
    "    print(\"-----------\")\n",
    "    if i==3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
